{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total lines in the file:  44873\n",
      "Sample of drug names:  ['prolensa', 'ssd', 'fluocinonide', 'cardizem cd', 'scemblix', 'carglumic acid', 'emsam', 'horizant', 'fexofenadine hydrochloride hives', 'synovalyte in plastic container']\n",
      "number of drugs:  5583\n"
     ]
    }
   ],
   "source": [
    "lst = set()\n",
    "formulation_set = set()\n",
    "avoided_formulation = [\"inject\", \"im-iv\", \"intravenous\", \"intra-articular\", \"intramuscular\"]\n",
    "\n",
    "def isAcceptedDrugFormulation (formulation):\n",
    "    for avoided_form in avoided_formulation:\n",
    "        if formulation.find(avoided_form) >= 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "with open (\"Products.txt\", \"r\") as f:\n",
    "    f.readline()\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        line_lst = line.split(\"\\t\")\n",
    "        formulation = line_lst[2].lower()\n",
    "        drugname = line_lst[5].lower()\n",
    "        if isAcceptedDrugFormulation(formulation):\n",
    "            lst.add(drugname)\n",
    "            formulation_set.add(formulation)\n",
    "        c += 1\n",
    "lst = list(lst)\n",
    "print(\"total lines in the file: \", c)\n",
    "print(\"Sample of drug names: \", list(lst)[:10])\n",
    "print(\"number of drugs: \", len(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate numpy array of drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide list of drug names in numpy in case my teammate needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5583,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugset_np = np.array(list(lst))\n",
    "drugset_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5583\n"
     ]
    }
   ],
   "source": [
    "print(len(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature generation step\n",
    "four types of error\n",
    "1. omission (missing one letter)\n",
    "2. transpose (order of two neighbor letters are incorrect)\n",
    "3. replacement\n",
    "a. vow-to-vow replacement\n",
    "b. consonant-to-consonant replacement\n",
    "4. insertion (insert random letter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def omission(drug, i):\n",
    "    if i == 0:\n",
    "        return drug[i+1:]\n",
    "    elif i == len(drug)-1:\n",
    "        return drug[:i]\n",
    "    else:\n",
    "        return drug[:i] + drug[i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcdef\n",
      "acdef\n",
      "abdef\n",
      "abcef\n",
      "abcdf\n",
      "abcde\n"
     ]
    }
   ],
   "source": [
    "drug = \"abcdef\"\n",
    "for i in range(len(drug)):\n",
    "    print(omission (drug, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(drug, i):\n",
    "    if i >= len(drug)-1-1:\n",
    "        i = len(drug)-2\n",
    "        return drug[:i] + drug[i+1] +drug[i]\n",
    "    else:\n",
    "        return drug[:i] + drug[i+1] +drug[i] + drug[i+2:]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "bacdef\n",
      "1\n",
      "acbdef\n",
      "2\n",
      "abdcef\n",
      "3\n",
      "abcedf\n",
      "4\n",
      "abcdfe\n",
      "5\n",
      "abcdfe\n"
     ]
    }
   ],
   "source": [
    "drug = \"abcdef\"\n",
    "for i in range(len(drug)):\n",
    "    print(i)\n",
    "    print(transpose(drug, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'e', 'i', 'o', 'u']\n",
      "['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n",
      "['a', 'e', 'i', 'o', 'u', 'b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "VOWELS = list(\"aeiou\")\n",
    "CONSONANTS = list(\"bcdfghjklmnpqrstvwxyz\")\n",
    "ALL_LETTERS = VOWELS + CONSONANTS\n",
    "\n",
    "print(VOWELS)\n",
    "print(CONSONANTS)\n",
    "print(ALL_LETTERS)\n",
    "def replace(drug, i):\n",
    "    c = drug[i].lower()\n",
    "    if c in VOWELS:\n",
    "        r = random.choice(VOWELS)\n",
    "    elif c in CONSONANTS:\n",
    "        r = random.choice(CONSONANTS)\n",
    "    else:\n",
    "        r = random.choice(ALL_LETTERS)\n",
    "    ans = drug[:i] + r + drug[i+1:]\n",
    "    if ans == drug:\n",
    "        replace(drug, i)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ubc__def\n",
      "1\n",
      "abc__def\n",
      "2\n",
      "abl__def\n",
      "3\n",
      "abcd_def\n",
      "4\n",
      "abc_xdef\n",
      "5\n",
      "abc__qef\n",
      "6\n",
      "abc__dif\n",
      "7\n",
      "abc__den\n"
     ]
    }
   ],
   "source": [
    "drug = \"abc__def\"\n",
    "for i in range(len(drug)):\n",
    "    print(i)\n",
    "    print(replace(drug, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'e', 'i', 'o', 'u', 'b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ALL_LETTERS = VOWELS + CONSONANTS\n",
    "\n",
    "print(ALL_LETTERS)\n",
    "\n",
    "def insertion(drug, i):\n",
    "    r = random.choice(ALL_LETTERS)\n",
    "    return drug[:i] + r + drug[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yabcdef\n",
      "akbcdef\n",
      "abwcdef\n",
      "abcfdef\n",
      "abcdnef\n",
      "abcdekf\n",
      "abcdefq\n"
     ]
    }
   ],
   "source": [
    "drug = \"abcdef\"\n",
    "for i in range(len(drug)+1):\n",
    "    print(insertion(drug, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this feature can be used for unsupervised learning and transformer data intake\n",
    "def genUnsprvFeatPair(drug):\n",
    "    temp = [omission(drug, i) for i in range(len(drug))]\n",
    "    temp += [transpose(drug, i) for i in range(len(drug)-1)]\n",
    "    temp += [replace(drug, i) for i in range(len(drug))]\n",
    "    temp += [insertion(drug, i) for i in range(len(drug))]\n",
    "    return [(x, drug) for x in temp]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rug name', 'drug name'), ('dug name', 'drug name'), ('drg name', 'drug name'), ('dru name', 'drug name'), ('drugname', 'drug name'), ('drug ame', 'drug name'), ('drug nme', 'drug name'), ('drug nae', 'drug name'), ('drug nam', 'drug name'), ('rdug name', 'drug name'), ('durg name', 'drug name'), ('drgu name', 'drug name'), ('dru gname', 'drug name'), ('drugn ame', 'drug name'), ('drug anme', 'drug name'), ('drug nmae', 'drug name'), ('drug naem', 'drug name'), ('prug name', 'drug name'), ('dpug name', 'drug name'), ('dreg name', 'drug name'), ('drup name', 'drug name'), ('druganame', 'drug name'), ('drug yame', 'drug name'), ('drug nome', 'drug name'), ('drug nage', 'drug name'), ('drug namu', 'drug name'), ('idrug name', 'drug name'), ('dhrug name', 'drug name'), ('drpug name', 'drug name'), ('drujg name', 'drug name'), ('drugf name', 'drug name'), ('drug uname', 'drug name'), ('drug nuame', 'drug name'), ('drug nafme', 'drug name'), ('drug namge', 'drug name')]\n"
     ]
    }
   ],
   "source": [
    "drug = \"drug name\"\n",
    "print(genUnsprvFeatPair(drug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: dictionary spreader: https://sparrow.dev/object-spread-operator-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this feature can be used for NLTK ML models (naive bayes, sklearn models)\n",
    "def genSprvFeatPair(drug):\n",
    "    temp = {f\"omission_{i}\":omission(drug, i) for i in range(len(drug))}\n",
    "    temp2 = {f\"transpose_{i}\": transpose(drug, i) for i in range(len(drug)-1)}\n",
    "    temp3 = {f\"replace_{i}\": replace(drug, i) for i in range(len(drug))}\n",
    "    temp4 = {f\"insertion_{i}\":insertion(drug, i) for i in range(len(drug))}\n",
    "    return [{**temp, **temp2, **temp3, **temp4}, drug]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'omission_0': 'rug', 'omission_1': 'dug', 'omission_2': 'drg', 'omission_3': 'dru', 'transpose_0': 'rdug', 'transpose_1': 'durg', 'transpose_2': 'drgu', 'replace_0': 'trug', 'replace_1': 'dkug', 'replace_2': 'drug', 'replace_3': 'druj', 'insertion_0': 'bdrug', 'insertion_1': 'dsrug', 'insertion_2': 'drrug', 'insertion_3': 'drucg'}, 'drug']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "drug = \"drug\"\n",
    "print(genSprvFeatPair(drug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5583"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rolensa', 'prolensa'), ('polensa', 'prolensa'), ('prlensa', 'prolensa'), ('proensa', 'prolensa'), ('prolnsa', 'prolensa'), ('prolesa', 'prolensa'), ('prolena', 'prolensa'), ('prolens', 'prolensa'), ('rpolensa', 'prolensa'), ('porlensa', 'prolensa')]\n",
      "294741\n"
     ]
    }
   ],
   "source": [
    "# unsprv_dataset only first 100. convert the whole dataset would cause too much time? \n",
    "Unsprv_dataset = sum([genUnsprvFeatPair(drug) for drug in lst[:]], [])\n",
    "print(Unsprv_dataset[:10])\n",
    "print(len(Unsprv_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'omission_0': 'rolensa', 'omission_1': 'polensa', 'omission_2': 'prlensa', 'omission_3': 'proensa', 'omission_4': 'prolnsa', 'omission_5': 'prolesa', 'omission_6': 'prolena', 'omission_7': 'prolens', 'transpose_0': 'rpolensa', 'transpose_1': 'porlensa', 'transpose_2': 'prloensa', 'transpose_3': 'proelnsa', 'transpose_4': 'prolnesa', 'transpose_5': 'prolesna', 'transpose_6': 'prolenas', 'replace_0': 'mrolensa', 'replace_1': 'pwolensa', 'replace_2': 'prelensa', 'replace_3': 'proxensa', 'replace_4': 'prolansa', 'replace_5': 'proletsa', 'replace_6': 'prolenka', 'replace_7': 'prolensi', 'insertion_0': 'kprolensa', 'insertion_1': 'pfrolensa', 'insertion_2': 'prsolensa', 'insertion_3': 'proplensa', 'insertion_4': 'prolhensa', 'insertion_5': 'prolelnsa', 'insertion_6': 'prolenlsa', 'insertion_7': 'prolensja'}, 'prolensa'], [{'omission_0': 'sd', 'omission_1': 'sd', 'omission_2': 'ss', 'transpose_0': 'ssd', 'transpose_1': 'sds', 'replace_0': 'fsd', 'replace_1': 'shd', 'replace_2': 'ssl', 'insertion_0': 'bssd', 'insertion_1': 'stsd', 'insertion_2': 'ssvd'}, 'ssd']]\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "supervised_dataset = [genSprvFeatPair(drug) for drug in lst[:1000]]\n",
    "print(supervised_dataset[:2])\n",
    "print(len(supervised_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size:  800\n",
      "length of features:  1000\n"
     ]
    }
   ],
   "source": [
    "split = 0.80\n",
    "size = int(len(supervised_dataset)*split)\n",
    "print(\"size: \", size)\n",
    "import random\n",
    "\n",
    "random.shuffle(supervised_dataset)\n",
    "print(\"length of features: \", len(supervised_dataset))\n",
    "train_set, test_set = supervised_dataset[:size], supervised_dataset[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy percent: 0.0\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(train_set)\n",
    "print(\"LinearSVC_classifier accuracy:\", (nltk.classify.accuracy(LinearSVC_classifier, test_set))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(train_set)\n",
    "print(\"LogisticRegression_classifier accuracy:\", (nltk.classify.accuracy(LogisticRegression_classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refrences:https://pythonprogramming.net/naive-bayes-classifier-nltk-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
